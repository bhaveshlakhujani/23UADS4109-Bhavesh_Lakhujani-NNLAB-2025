{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838d6a73",
      "metadata": {
        "id": "838d6a73"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b48962",
      "metadata": {
        "id": "64b48962",
        "outputId": "f89b972e-de1a-4862-c673-b62115182280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14982 images belonging to 2 classes.\n",
            "Found 3745 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_path = r\"C:\\Users\\LENOVO\\Desktop\\Python\\Datasets\\Alzeimehers\\Data\"\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                             validation_split=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             zoom_range=0.2)\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(data_path,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=128,\n",
        "                                              class_mode='binary',\n",
        "                                              subset='training')\n",
        "\n",
        "val_generator = data_gen.flow_from_directory(data_path,\n",
        "                                            target_size=(224, 224),\n",
        "                                            batch_size=128,\n",
        "                                            class_mode='binary',\n",
        "                                            subset='validation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b1e1e8",
      "metadata": {
        "id": "95b1e1e8",
        "outputId": "498457ec-f07d-47db-c7f3-2868b1a69f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Mild_Dementia': 0, 'Very_mild_Dementia': 1}\n"
          ]
        }
      ],
      "source": [
        "print(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13aa11f4",
      "metadata": {
        "id": "13aa11f4",
        "outputId": "e113da48-ecd8-43c6-b64b-27d690716647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: np.float64(1.8718140929535232), 1: np.float64(0.6822404371584699)}\n"
          ]
        }
      ],
      "source": [
        "class_indices = train_generator.class_indices\n",
        "classes = list(class_indices.values())\n",
        "\n",
        "labels = train_generator.classes\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "print(class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fb185c",
      "metadata": {
        "id": "64fb185c",
        "outputId": "02034bd2-971e-4ed6-e22b-fbfe539c24b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b4e199",
      "metadata": {
        "id": "c7b4e199"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', 'precision', 'recall'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "849395bc",
      "metadata": {
        "id": "849395bc"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,\n",
        "          validation_data=val_generator,\n",
        "          epochs=10,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f00dda2",
      "metadata": {
        "id": "7f00dda2"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train loss', 'val loss'])\n",
        "plt.title('Loss per Epoch');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a766c1f6",
      "metadata": {
        "id": "a766c1f6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.title('Accuracy');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description of the Model  \n",
        "The model is built using transfer learning by leveraging the VGG16 architecture pretrained on the ImageNet dataset.   \n",
        "\n",
        "Key aspects:   \n",
        "VGG16 Base: The convolutional layers of VGG16 are used as a fixed feature extractor (trainable=False).\n",
        "\n",
        "Custom Top Layers:  \n",
        "Flatten layer to convert feature maps to a vector.   \n",
        "Dense(256) fully connected layer with ReLU activation.   \n",
        "Dropout(0.5) to prevent overfitting.   \n",
        "Dense(1) output layer with sigmoid activation for binary classification (Alzheimer’s vs Healthy).\n",
        "\n",
        "Loss Function:   \n",
        "binary_crossentropy, suitable for binary classification.  \n",
        "Optimizer:   \n",
        "Adam with a learning rate of 1e-4.  \n",
        "Metrics: Accuracy, Precision, and Recall are tracked."
      ],
      "metadata": {
        "id": "lkfgyZM6vero"
      },
      "id": "lkfgyZM6vero"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description of the Code   \n",
        "ImageDataGenerator is used for:   \n",
        "Rescaling pixel values to [0, 1]   \n",
        "Data augmentation (horizontal flip and zoom)   \n",
        "Splitting data into training (80%) and validation (20%) subsets.   \n",
        "Class Weights are computed using sklearn.utils.compute_class_weight to handle class imbalance.\n",
        "\n",
        "Transfer Learning:   \n",
        "VGG16 is loaded with pretrained ImageNet weights (excluding top classification layers).   \n",
        "All convolutional layers are frozen.  \n",
        "Custom dense layers are added for classification.\n",
        "\n",
        "Model Compilation:   \n",
        "Optimizer: Adam   \n",
        "Loss: binary_crossentropy   \n",
        "Metrics: accuracy, precision, recall.\n",
        "\n",
        "Model Training:   \n",
        "Trained for 10 epochs with the augmented data generators.\n",
        "\n",
        "Performance Visualization:       \n",
        "Loss and accuracy plots are generated for both training and validation sets across epochs.\n",
        "\n",
        "Performance   \n",
        "After training for 10 epochs:  \n",
        "Training and Validation Accuracy trends are visualized.  \n",
        "Loss and Accuracy Curves are plotted:\n",
        "\n",
        "Helps detect overfitting/underfitting.   \n",
        "Shows how well the model is learning over time.   \n",
        "(Actual numeric values aren't shown here since they're runtime dependent, but your code correctly tracks and plots them.)"
      ],
      "metadata": {
        "id": "AVnuX3iKxPp6"
      },
      "id": "AVnuX3iKxPp6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Comments\n",
        "Using pretrained Architectures can significantly Increase Model performance.   \n",
        "Using transfer learning saves a lot of time and resources that would have been spent on model training and architecture development"
      ],
      "metadata": {
        "id": "3GW-jSDR0cmi"
      },
      "id": "3GW-jSDR0cmi"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}